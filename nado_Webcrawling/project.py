# [ì˜¤ëŠ˜ì˜ ë‚ ì”¨]
'''
íë¦¼, ì–´ì œë³´ë‹¤ OOÂ°C ë†’ì•„ìš”.
í˜„ì¬ OOÂ°C (ìµœì € OOÂ° / ìµœê³  OOÂ°)
ì˜¤ì „ ê°•ìˆ˜í™•ë¥  OO% / ì˜¤í›„ ê°•ìˆ˜í™•ë¥  OO%

ë¯¸ì„¸ë¨¼ì§€ OO ì¢‹ìŒ
ì´ˆë¯¸ì„¸ë¨¼ì§€ OO ì¢‹ìŒ 
'''

import requests
from bs4 import BeautifulSoup

def scrape_weather() : 
  print("[ì˜¤ëŠ˜ì˜ ë‚ ì”¨]")
  url = "https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EC%84%9C%EC%9A%B8+%EB%82%A0%EC%94%A8&oquery=%EA%B2%BD%EA%B8%B0%EB%8F%84+%EC%9A%A9%EC%9D%B8%EC%8B%9C+%EA%B8%B0%ED%9D%A5%EA%B5%AC+%EA%B5%AC%EA%B0%88%EB%8F%99+%EB%AF%B8%EC%84%B8%EB%A8%BC%EC%A7%80&tqi=ig%2BwtwqVN8VssuOrpy0ssssss48-115725"
  res = requests.get(url)
  res.raise_for_status()
  soup = BeautifulSoup(res.text, "lxml")
  # íë¦¼, ì–´ì œë³´ë‹¤ OOÂ°C ë†’ì•„ìš”. 
  cast = soup.find("p", attrs={"class" : "summary"}).get_text().split()
  # í˜„ì¬ OOÂ°C (ìµœì € OOÂ° / ìµœê³  OOÂ°) 
  curr_temp = soup.find("div", attrs={"class":"temperature_text"}).get_text()  # ë§Œì•½ íƒœê·¸ë¥¼ ê°€ì ¸ì˜¬ ë•Œ í•´ë‹¹ íƒœê·¸ ì•ˆì— ë¶ˆí•„ìš”í•œ ë°ì´í„°ê°€ ìˆë‹¤ë©´, replace ë¥¼ ì¨ì„œ ë¹ˆì¹¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì.
  min_temp = soup.find("span", attrs={"class": "lowest"}).get_text()
  max_temp = soup.find("span", attrs={"class": "highest"}).get_text()
  # ì˜¤ì „ ê°•ìˆ˜í™•ë¥  OO% / ì˜¤í›„ ê°•ìˆ˜í™•ë¥  OO%
  rain_rate = soup.find_all("span", attrs={"class":"weather_left"})

  # afternoon_rain_rate = soup.find("span", attrs={"class":"weather_inner"}).get_text() 

  # ì¶œë ¥ 
  print(f" {cast[0]} {cast[1]} {cast[2]}ğŸ’¡ ({cast[3]})")
  print("{} ({} / {})".format(curr_temp, min_temp, max_temp))
  print(f" ê°•ìˆ˜í™•ë¥  {rain_rate[0].get_text()} / {rain_rate[1].get_text()} ")



if __name__ == "__main__" : 
  scrape_weather() # ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸° 
