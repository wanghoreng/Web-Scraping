# [ì˜¤ëŠ˜ì˜ ë‚ ì”¨]
'''
íë¦¼, ì–´ì œë³´ë‹¤ OOÂ°C ë†’ì•„ìš”.
í˜„ìž¬ OOÂ°C (ìµœì € OOÂ° / ìµœê³  OOÂ°)
ì˜¤ì „ ê°•ìˆ˜í™•ë¥  OO% / ì˜¤í›„ ê°•ìˆ˜í™•ë¥  OO%

ë¯¸ì„¸ë¨¼ì§€ OO ì¢‹ìŒ
ì´ˆë¯¸ì„¸ë¨¼ì§€ OO ì¢‹ìŒ 
'''

import requests
import re
from bs4 import BeautifulSoup
import json


# ì¹´ì¹´ì˜¤í†¡ Access í† í° => 12ì‹œê°„ ë§ˆë‹¤ ë§Œë£Œ
KAKAO_TOKEN = "qhWB_b4tp69tjD2P2Ow803VnDVjGL5tAHzUKKiWQAAABi84Np9D-oZq-Jypvmw"

# ì¹´ì¹´ì˜¤í†¡ API ë¥¼ í†µí•´ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜ 
def sendTo_Kakao(text) :
  headers = {"Authorization":"Bearer " + KAKAO_TOKEN}
  url = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
  post = {
    "object_type": "text",
        "text": text,
        "link": {
            "web_url": "https://developers.kakao.com",
            "mobile_web_url": "https://developers.kakao.com"
        },
        "button_title": "ë°”ë¡œ í™•ì¸"
  }

  data = {"template_object": json.dumps(post)}
  return requests.post(url, headers=headers, data=data)


# bs4 ë¥¼ í†µí•´ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ 
def create_soup(url) : 

  headers = {"User-Agent" : "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36"}

  try:
    res = requests.get(url, headers=headers)
    res.raise_for_status()  # HTTPError ë°œìƒ ê°€ëŠ¥
    soup = BeautifulSoup(res.text, "lxml")
    return soup
  except requests.exceptions.RequestException as e:
      print("Error occurred: ", e)
      sendTo_Kakao("ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤. í™•ì¸í•´ì£¼ì„¸ìš”.")


# ë‚ ì”¨ì •ë³´ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ 
def scrape_weather() : 
  weather_text = ""
  weather_text += "[ì˜¤ëŠ˜ì˜ ë‚ ì”¨]\n"
  url = "https://weather.naver.com/today/09545101?cpName=KMA"
  soup = create_soup(url)
  
  # íë¦¼, ì–´ì œë³´ë‹¤ OOÂ°C ë†’ì•„ìš”. 
  cast = soup.find("p", attrs={"class" : "summary"}).get_text().split()
  #í˜„ìž¬ OOÂ°C (ìµœì € OOÂ° / ìµœê³  OOÂ°) 
  curr_temp = soup.find("strong", attrs={"class":"current"}).get_text().strip()  # ë§Œì•½ íƒœê·¸ë¥¼ ê°€ì ¸ì˜¬ ë•Œ í•´ë‹¹ íƒœê·¸ ì•ˆì— ë¶ˆí•„ìš”í•œ ë°ì´í„°ê°€ ìžˆë‹¤ë©´, replace ë¥¼ ì¨ì„œ ë¹ˆì¹¸ìœ¼ë¡œ ë°”ê¿”ì£¼ìž.
  min_temp = soup.find("span", attrs={"class": "lowest"}).get_text().strip()
  max_temp = soup.find("span", attrs={"class": "highest"}).get_text().strip()
  # ì˜¤ì „ ê°•ìˆ˜í™•ë¥  OO% / ì˜¤í›„ ê°•ìˆ˜í™•ë¥  OO%
  rain_rate = soup.find_all("strong", attrs={"class":"inner_text"})
  morning_RR = rain_rate[0].get_text().split()
  afternoon_RR = rain_rate[1].get_text().split()


  # ì¶œë ¥ 
  weather_text += f"{cast[0]} / {cast[1]} {cast[2]} {cast[3]}ðŸ’¡\n"
  weather_text += "{} ({} / {})\n".format(curr_temp, min_temp, max_temp)
  weather_text += f"{morning_RR[0]} {morning_RR[1]} | {afternoon_RR[0]} {afternoon_RR[1]}\n\n"

  
  pattern = "ìµœê³ ê¸°ì˜¨([0-9]+)"
  result = re.search(pattern, max_temp)
  match = int(result.group(1))
  if match >= 7 and match <= 13: 
    weather_text += "ì˜¤ëŠ˜ì€ ë§¨íˆ¬ë§¨ì— í›„ë¦¬ìŠ¤ë‹·!!ðŸ§¥ íŽ¸í•˜ê²Œ ê°€ìžê³ ~!"
  elif match >= 1 and match <= 6 : 
    weather_text += "ì˜¤ëŠ˜ì€ íŒ¨ë”© ì•ˆìž…ìœ¼ë©´ ì¶¥ê² ëŠ”ë””?? ðŸ¤§ ê°ê¸° ì¡°ì‹¬í˜€!!"
  elif match <= 0 :   
    weather_text += "ì§„ì§œ ì˜¤ëŠ˜ì€ ë‚ ì”¨ ë¯¸ì³¤ì–´!! ìž¥ê°‘ðŸ§¤ì´ëž‘ ëª©ë„ë¦¬ðŸ§£ ê¼­ ì±™ê²¨!"
  else : 
    weather_text += "ê²¨ìš¸ì•„ë‹Œ ë‚ ì”¨ëŠ” ìž˜ ì±™ê²¨ìž…ì„ ìˆ˜ ìžˆì§€?? ã…Žã…‹ã…‹ íŒ¨ì…˜ ì±™ê¸°ìž~ ðŸ¯"

  r = sendTo_Kakao(weather_text)
  print(r.text)



if __name__ == "__main__" : 
  scrape_weather() # ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸° 